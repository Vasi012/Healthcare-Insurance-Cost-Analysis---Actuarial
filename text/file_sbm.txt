# etl_pipeline.py

def extract(file_path):
    """Extract data from a CSV file."""
    if os.path.exists(file_path):
        data = pd.read_csv(file_path)
        return data
    else:
        raise FileNotFoundError(f"The file {file_path} does not exist.")

def transform(data):
    """Transform the data by cleaning and preparing it."""
    # Example transformation: Drop rows with missing values
    data_cleaned = data.dropna()
    return data_cleaned

def load(data, output_path):
    """Load the transformed data into a new CSV file."""
    data.to_csv(output_path, index=False)
    print(f"Data successfully saved to {output_path}")

if __name__ == "__main__":
    # Example usage
    input_file = "input_data.csv"  # Replace with your input file path
    output_file = "output_data.csv"  # Replace with your output file path

    try:
        # ETL process
        raw_data = extract(input_file)
        transformed_data = transform(raw_data)
        load(transformed_data, output_file)
    except Exception as e:
        print(f"ETL process failed: {e}")

        